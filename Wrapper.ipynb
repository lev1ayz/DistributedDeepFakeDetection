{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33661713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "import numpy as np\n",
    "import fileinput\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributed as dist\n",
    "import models\n",
    "from dfd_utils.FaceForensicsDataset import FaceForensicsDataset\n",
    "from dfd_utils.utils import plot_images, get_embeddings, plot_embeddings_2D, plot_embeddings_3D\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm \n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import cm\n",
    "\n",
    "from torchvision import transforms, utils, datasets\n",
    "import cv2\n",
    "from facenet_pytorch import MTCNN\n",
    "import random\n",
    "\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521878d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tabulate\n",
    "!pip install configargparse\n",
    "!pip install filelock\n",
    "!pip install strconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb350c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE_PATH = \"/srv/DeepFakeDetection/andrew_atonov_simclr_pytorch/simclr-pytorch/configs/generic_config.yaml\"\n",
    "#cifar_train_epochs1000_bs1024.yaml\n",
    "#ff_train.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc823086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify params in the file\n",
    "batch_size = 32\n",
    "eval_only = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc6536d",
   "metadata": {},
   "source": [
    "## Train Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7239120b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(ckpt='', config_file='./configs/cifar_train_epochs1000_bs1024.yaml', deepfakes=False, dist='ddp', dist_address='127.0.0.1:1234', eval_freq=4800, eval_only=False, iters=48000, log_freq=48, lr=4.0, lr_schedule='warmup-anneal', name='reproduce-cifar10', node_rank=0, opt='lars', problem='sim-clr', save_freq=4800, seed=-1, tmp=False, verbose=True, warmup=0.01, weight_decay=1e-06, workers=2, world_size=1)\n",
      "arch: ResNet50\n",
      "aug: true\n",
      "batch_size: 128\n",
      "ckpt: ''\n",
      "color_dist_s: 0.5\n",
      "config_file: ./configs/cifar_train_epochs1000_bs1024.yaml\n",
      "data: cifar\n",
      "deepfakes: false\n",
      "dist: ddp\n",
      "dist_address: 127.0.0.1:1234\n",
      "eval_freq: 4800\n",
      "eval_only: false\n",
      "iters: 48000\n",
      "log_freq: 48\n",
      "lr: 4.0\n",
      "lr_schedule: warmup-anneal\n",
      "multiplier: 2\n",
      "name: reproduce-cifar10\n",
      "node_rank: 0\n",
      "opt: lars\n",
      "problem: sim-clr\n",
      "root: /srv/DeepFakeDetection/andrew_atonov_simclr_pytorch/simclr-pytorch/logs/exman-train.py/runs/000143\n",
      "save_freq: 4800\n",
      "scale_lower: 0.08\n",
      "seed: -1\n",
      "sync_bn: true\n",
      "temperature: 0.5\n",
      "tmp: false\n",
      "verbose: true\n",
      "warmup: 0.01\n",
      "weight_decay: 1.0e-06\n",
      "workers: 2\n",
      "world_size: 1\n",
      "\n",
      "time: '2021-09-20T15:07:43'\n",
      "id: 143\n",
      "\n",
      "Created symlink from /srv/DeepFakeDetection/andrew_atonov_simclr_pytorch/simclr-pytorch/logs/exman-train.py/index/000143.yaml -> ../runs/000143/params.yaml\n",
      "args: Namespace(arch='ResNet50', aug=True, batch_size=128, ckpt='', color_dist_s=0.5, config_file='./configs/cifar_train_epochs1000_bs1024.yaml', data='cifar', deepfakes=False, dist='ddp', dist_address='127.0.0.1:1234', eval_freq=4800, eval_only=False, iters=48000, log_freq=48, lr=4.0, lr_schedule='warmup-anneal', multiplier=2, name='reproduce-cifar10', node_rank=0, opt='lars', problem='sim-clr', root=PosixPath('/srv/DeepFakeDetection/andrew_atonov_simclr_pytorch/simclr-pytorch/logs/exman-train.py/runs/000143'), save_freq=4800, scale_lower=0.08, seed=-1, sync_bn=True, temperature=0.5, tmp=False, verbose=True, warmup=0.01, weight_decay=1e-06, workers=2, world_size=1)\n",
      "===> 1 GPUs total; batch_size=128 per GPU\n",
      "===> Proc 0/1@shirbar-WS-C621E-SAGE-Series\n",
      "ddp\n",
      "** Using avgpool **\n",
      "======> Encoder: output dim 2048 | 25.549M parameters\n",
      "preparing data\n",
      "transforms for SIMCLR\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Process 0: 50000 training samples per epoch\n",
      "Process 0: 10000 test samples\n",
      "  0%|                                      | 22/48000 [00:16<4:57:05,  2.69it/s]^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 300, in <module>\n",
      "    main()\n",
      "  File \"train.py\", line 104, in main\n",
      "    args=(ngpus, args),\n",
      "  File \"/home/leva1/.conda/envs/simclr_pytorch/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\", line 199, in spawn\n",
      "    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n",
      "  File \"/home/leva1/.conda/envs/simclr_pytorch/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\", line 157, in start_processes\n",
      "    while not context.join():\n",
      "  File \"/home/leva1/.conda/envs/simclr_pytorch/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\", line 77, in join\n",
      "    timeout=timeout,\n",
      "  File \"/home/leva1/.conda/envs/simclr_pytorch/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/leva1/.conda/envs/simclr_pytorch/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "cmd = f'python train.py --config {CONFIG_FILE_PATH}'\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad58152",
   "metadata": {},
   "source": [
    "## Eval Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b871358",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(ckpt='', config_file='./configs/cifar_train_epochs1000_bs1024.yaml', deepfakes=False, dist='ddp', dist_address='127.0.0.1:1234', eval_freq=4800, eval_only=True, iters=48000, log_freq=48, lr=4.0, lr_schedule='warmup-anneal', name='reproduce-cifar10', node_rank=0, opt='lars', problem='sim-clr', save_freq=4800, seed=-1, tmp=False, verbose=True, warmup=0.01, weight_decay=1e-06, workers=2, world_size=1)\n",
      "arch: ResNet50\n",
      "aug: true\n",
      "batch_size: 128\n",
      "ckpt: ''\n",
      "color_dist_s: 0.5\n",
      "config_file: ./configs/cifar_train_epochs1000_bs1024.yaml\n",
      "data: cifar\n",
      "deepfakes: false\n",
      "dist: ddp\n",
      "dist_address: 127.0.0.1:1234\n",
      "eval_freq: 4800\n",
      "eval_only: true\n",
      "iters: 48000\n",
      "log_freq: 48\n",
      "lr: 4.0\n",
      "lr_schedule: warmup-anneal\n",
      "multiplier: 2\n",
      "name: reproduce-cifar10\n",
      "node_rank: 0\n",
      "opt: lars\n",
      "problem: sim-clr\n",
      "root: /srv/DeepFakeDetection/andrew_atonov_simclr_pytorch/simclr-pytorch/logs/exman-train.py/runs/000144\n",
      "save_freq: 4800\n",
      "scale_lower: 0.08\n",
      "seed: -1\n",
      "sync_bn: true\n",
      "temperature: 0.5\n",
      "tmp: false\n",
      "verbose: true\n",
      "warmup: 0.01\n",
      "weight_decay: 1.0e-06\n",
      "workers: 2\n",
      "world_size: 1\n",
      "\n",
      "time: '2021-09-20T15:15:38'\n",
      "id: 144\n",
      "\n",
      "Created symlink from /srv/DeepFakeDetection/andrew_atonov_simclr_pytorch/simclr-pytorch/logs/exman-train.py/index/000144.yaml -> ../runs/000144/params.yaml\n",
      "args: Namespace(arch='ResNet50', aug=True, batch_size=128, ckpt='', color_dist_s=0.5, config_file='./configs/cifar_train_epochs1000_bs1024.yaml', data='cifar', deepfakes=False, dist='ddp', dist_address='127.0.0.1:1234', eval_freq=4800, eval_only=True, iters=48000, log_freq=48, lr=4.0, lr_schedule='warmup-anneal', multiplier=2, name='reproduce-cifar10', node_rank=0, opt='lars', problem='sim-clr', root=PosixPath('/srv/DeepFakeDetection/andrew_atonov_simclr_pytorch/simclr-pytorch/logs/exman-train.py/runs/000144'), save_freq=4800, scale_lower=0.08, seed=-1, sync_bn=True, temperature=0.5, tmp=False, verbose=True, warmup=0.01, weight_decay=1e-06, workers=2, world_size=1)\n",
      "===> 1 GPUs total; batch_size=128 per GPU\n",
      "===> Proc 0/1@shirbar-WS-C621E-SAGE-Series\n",
      "ddp\n",
      "** Using avgpool **\n",
      "======> Encoder: output dim 2048 | 25.549M parameters\n",
      "preparing data\n",
      "transforms for SIMCLR\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Process 0: 50000 training samples per epoch\n",
      "Process 0: 10000 test samples\n",
      "  0%|                                                 | 0/48000 [00:00<?, ?it/s]/home/leva1/.conda/envs/simclr_pytorch/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "  0%|                                      | 47/48000 [00:12<1:39:27,  8.04it/s]  t       lr    data_time    it_time\n",
      "---  -------  -----------  ---------\n",
      " 48  4.0e-01       12.752     12.752\n",
      "  0%|                                      | 95/48000 [00:18<1:42:07,  7.82it/s] 96  8.0e-01        5.542      5.543\n",
      "  0%|                                     | 143/48000 [00:24<1:37:56,  8.14it/s]144  1.2e+00        5.632      5.633\n",
      "  0%|▏                                    | 191/48000 [00:30<1:36:02,  8.30it/s]192  1.6e+00        5.541      5.541\n",
      "  0%|▏                                    | 239/48000 [00:36<1:33:37,  8.50it/s]240  2.0e+00        5.374      5.374\n",
      "  1%|▏                                    | 287/48000 [00:41<1:35:13,  8.35it/s]288  2.4e+00        5.397      5.397\n",
      "  1%|▏                                    | 313/48000 [00:45<1:39:16,  8.01it/s]^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 300, in <module>\n",
      "  1%|▏                                    | 314/48000 [00:45<1:54:27,  6.94it/s]\n",
      "    main()\n",
      "  File \"train.py\", line 104, in main\n",
      "    args=(ngpus, args),\n",
      "  File \"/home/leva1/.conda/envs/simclr_pytorch/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\", line 199, in spawn\n",
      "    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n",
      "  File \"/home/leva1/.conda/envs/simclr_pytorch/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\", line 157, in start_processes\n",
      "    while not context.join():\n",
      "  File \"/home/leva1/.conda/envs/simclr_pytorch/lib/python3.6/site-packages/torch/multiprocessing/spawn.py\", line 77, in join\n",
      "    timeout=timeout,\n",
      "  File \"/home/leva1/.conda/envs/simclr_pytorch/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/leva1/.conda/envs/simclr_pytorch/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Eval base modelb\n",
    "cmd = f'python train.py --config {CONFIG_FILE_PATH} --eval_only True'\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05705c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccb65b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train classificaiton Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f51e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0274506b",
   "metadata": {},
   "source": [
    "## Plot Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c544278",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb3ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi']=300\n",
    "device = torch.device('cuda')\n",
    "dist.init_process_group(\n",
    "            backend='nccl',\n",
    "            init_method='tcp://%s' % 'localhost:8882',\n",
    "            world_size=1,\n",
    "            rank=0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b46bb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint: /media/shirbar/My Passport/trained_models/simclr_original_augs_pretrained_resnet.pth.tar  ...\n",
      "checkpoint loaded!\n",
      "loading model...\n",
      "device is: cuda\n",
      "ddp\n",
      "** Removing original FC layer **\n",
      "** Using avgpool **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/leva1/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3252fb9052cb4b64b3384b39549fe466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Loading pretrained ResNet50 weights **\n",
      "======> Encoder: output dim 2048 | 23.508M parameters\n",
      "ssl.__init__:device is: cuda\n",
      "hparams.gpu : 0\n",
      "model loaded!\n"
     ]
    }
   ],
   "source": [
    "MODELS_FOLDER = '/media/shirbar/My Passport/trained_models'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "chkpt_path = f'{MODELS_FOLDER}/simclr_original_augs_pretrained_resnet.pth.tar'\n",
    "print('loading checkpoint:', chkpt_path, ' ...')\n",
    "chkpt = torch.load(chkpt_path,\n",
    "                    map_location=device)\n",
    "print('checkpoint loaded!')\n",
    "\n",
    "print('loading model...')\n",
    "model = models.ssl.SimCLR.load(chkpt, device=device)\n",
    "model.eval()\n",
    "print('model loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4572e6",
   "metadata": {},
   "source": [
    "### Load FaceForensics Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbcf42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ff_ds_test(wanted_ds_size,\n",
    "                    batch_size,\n",
    "                    load_deepfakes=False,\n",
    "                    load_face2face=False,\n",
    "                    load_neural_textures=False,\n",
    "                    masking_transforms=False,\n",
    "                    transform=None):\n",
    "    TEST_DATASET_PATH = '/media/shirbar/My Passport/FaceForensics/split_ds/test'\n",
    "    ff_ds_test  = FaceForensicsDataset(TEST_DATASET_PATH,\n",
    "                                    transform=None,\n",
    "                                    load_deepfakes=load_deepfakes,\n",
    "                                    load_face2face=load_face2face,\n",
    "                                    load_neural_textures=load_neural_textures,\n",
    "                                  masking_transforms=masking_transforms)\n",
    "\n",
    "    ff_ds_test_len = len(ff_ds_test)\n",
    "    wanted_ds_size = wanted_ds_size if ff_ds_test_len > wanted_ds_size else ff_ds_test_len\n",
    "    random_indices = random.sample(range(0,ff_ds_test_len), wanted_ds_size)\n",
    "    test_subset = Subset(ff_ds_test, random_indices)\n",
    "\n",
    "    test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "    print('test size:', test_subset.__len__())\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8e8fb9",
   "metadata": {},
   "source": [
    "## Deepfakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1d2896a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading real images...\n",
      "real images loaded!\n",
      "loading deepfakes...\n",
      "deepfakes loaded!\n",
      "real imgs len: 73768\n",
      "masks len: 73768\n",
      "fakes imgs len: 73770\n",
      "fakes masks len: 73770\n",
      "final imgs len: 147538\n",
      "final masks len: 147538\n",
      "asserting order\n",
      "assertion passed!\n",
      "test size: 2000\n"
     ]
    }
   ],
   "source": [
    "test_loader = load_ff_ds_test(2000, 16, load_deepfakes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f178e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 66/125 [2:23:08<1:30:08, 91.66s/it] "
     ]
    }
   ],
   "source": [
    "embeds, targets = get_embeddings(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4731438",
   "metadata": {},
   "source": [
    "### Plot example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, _, targets = next(iter(test_loader))\n",
    "plot_images(images, targets.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b06bab",
   "metadata": {},
   "source": [
    "### 2D Embeddings - Deepfakes + Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b62fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings_2D(embeds, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1452a",
   "metadata": {},
   "source": [
    "### 3D Embeddings - Deepfakes + Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90410bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_embeddings_3D(embeds, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbd3204",
   "metadata": {},
   "source": [
    "## Face2Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8798cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = load_ff_ds_test(2000, 16, load_face2face=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb94147",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds, targets = get_embeddings(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715efaa1",
   "metadata": {},
   "source": [
    "### Plot example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2780c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, _, targets = next(iter(test_loader))\n",
    "plot_images(images, targets.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c4d5ab",
   "metadata": {},
   "source": [
    "### 2D Embeddings - Face2Face + Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154dae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_embeddings_2D(embeds, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e4f650",
   "metadata": {},
   "source": [
    "### 3D Embeddings - Face2Face + Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b6d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_embeddings_3D(embeds, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a14750",
   "metadata": {},
   "source": [
    "## NeuralTextures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d94a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = load_ff_ds_test(2000, 16, load_neural_textures=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2bf86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds, targets = get_embeddings(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8e615c",
   "metadata": {},
   "source": [
    "### Plot example images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28be4d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, _, targets = next(iter(test_loader))\n",
    "plot_images(images, targets.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b312a",
   "metadata": {},
   "source": [
    "### 2D Embeddings - NeuralTextures + Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c98be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings_2D(embeds, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08142b97",
   "metadata": {},
   "source": [
    "### 3D Embeddings - NeuralTextures + Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c611f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_embeddings_3D(embeds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08897e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed25999c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301d4060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afa8fe3e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "trying to initialize the default process group twice!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-3b445f3d6899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.dpi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m dist.init_process_group(\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nccl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0minit_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tcp://%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m'localhost:8882'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/DeepFakeDetection/venv/dfd-env/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36minit_process_group\u001b[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mGroupMember\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWORLD\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         raise RuntimeError(\"trying to initialize the default process group \"\n\u001b[0m\u001b[1;32m    485\u001b[0m                            \"twice!\")\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: trying to initialize the default process group twice!"
     ]
    }
   ],
   "source": [
    "plt.rcParams['figure.dpi']=300\n",
    "device = torch.device('cuda')\n",
    "dist.init_process_group(\n",
    "            backend='nccl',\n",
    "            init_method='tcp://%s' % 'localhost:8882',\n",
    "            world_size=1,\n",
    "            rank=0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e65b12b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is: cuda\n",
      "ddp\n",
      "** Removing original FC layer **\n",
      "** Using avgpool **\n",
      "======> Encoder: output dim 2048 | 23.508M parameters\n",
      "ssl.__init__:device is: cuda\n",
      "hparams.gpu : 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (model): DistributedDataParallel(\n",
       "    (module): EncodeProject(\n",
       "      (convnet): ResNet50(\n",
       "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (layer1): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "        (fc): None\n",
       "      )\n",
       "      (projection): Sequential(\n",
       "        (fc1): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (bn1): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU()\n",
       "        (fc2): Linear(in_features=2048, out_features=128, bias=False)\n",
       "        (bn2): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (criterion): NTXent()\n",
       ")"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "chkpt = torch.load(\n",
    "    '/media/shirbar/My Passport/trained_models/simclr_original_augs_pretrained_resnet.pth.tar',\n",
    "    map_location=device)\n",
    "model = models.ssl.SimCLR.load(ckpt, device=device)\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
